{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from InceptionTime import Latent, InceptionBlock\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TimeSeriesClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = InceptionBlock(\n",
    "            in_channels=1,\n",
    "            n_filters=8,\n",
    "            kernel_sizes=[9, 19, 39],\n",
    "            bottleneck_channels=32,\n",
    "            use_residual=True,\n",
    "            activation=nn.ReLU(),\n",
    "            return_indices=True\n",
    "        )\n",
    "        \n",
    "        self.latent = Latent()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_len)\n",
    "        x = x.unsqueeze(1)  # x shape: (batch_size, 1, sequence_len)\n",
    "        x, indices = self.encoder(x)\n",
    "        x, _ = self.latent(x, indices)\n",
    "        x = x.squeeze(dim=3)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classifier=TimeSeriesClassifier(input_size=1, hidden_size=32, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_classifier.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "for param in model_classifier.classifier.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "def accuracy(outputs, targets):\n",
    "    with torch.no_grad():\n",
    "        predicted = outputs\n",
    "        correct = predicted.eq(targets).sum().item()\n",
    "        accuracy = correct / targets.numel()\n",
    "    return accuracy\n",
    "\n",
    "def precision(outputs, targets):\n",
    "    with torch.no_grad():\n",
    "        predicted = outputs\n",
    "        true_positives = (predicted * targets).sum().item()\n",
    "        false_positives = ((predicted == 1) & (targets == 0)).sum().item()\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "    return precision\n",
    "\n",
    "# Создание пустого списка для потерь\n",
    "loss_list=[]\n",
    "\n",
    "# Определение устройства для вычислений\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Перемещаем модель на вычислительное устройство\n",
    "model_classifier.to(device)\n",
    "\n",
    "# Выводим использованное вычислительное устройство\n",
    "print(device)\n",
    "\n",
    "# Определение количества эпох для обучения\\nnum_epochs = 30\n",
    "\n",
    "# Определение функции потерь\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Определение оптимизатора и скорости обучения\n",
    "optimizer = optim.Adam(model_classifier.parameters(), lr=0.00005)\n",
    "\n",
    "# Инициализация переменной для лучшей потери\n",
    "best_loss = float('inf')\n",
    "\n",
    "# Начало цикла обучения на num_epochs эпох\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Инициализация переменных для подсчета потерь и метрик\n",
    "    running_loss = 0.0\n",
    "    run_acc=0.0\n",
    "    prec_acc=0.0\n",
    "\n",
    "    # Переводим модель в режим обучения\n",
    "    model_classifier.train()\n",
    "\n",
    "    # Начало цикла по обучающим данным\n",
    "    for data in tqdm(train_dataloader):\n",
    "\n",
    "        # Перемещаем данные и метки на вычислительное устройство\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Обнуляем градиенты\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Прямой проход: вычисляем выход модели для входных данных\n",
    "        outputs = model_classifier(inputs)\n",
    "\n",
    "        # Вычисляем функцию потерь\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "\n",
    "        # Обратный проход и оптимизация параметров\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Суммируем потери по батчам\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # Начало цикла по тестовым данным\n",
    "    val_loss = 0\n",
    "    model_classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        run_acc_test=0.0\n",
    "        prec_acc_test=0.0\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Прямой проход: вычисляем выход модели для входных данных\n",
    "            outputs = model_classifier(inputs)\n",
    "\n",
    "            # Вычисляем функцию потерь\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "\n",
    "            # Суммируем потери по батчам\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Считаем метрику accuracy\n",
    "        run_acc_test += accuracy(outputs, labels)\n",
    "        \n",
    "        # Считаем метрику precision\n",
    "        prec_acc_test += precision(outputs, labels)\n",
    "\n",
    "    # Общая оценка потерь на тестовой выборке\n",
    "    val_loss = _loss / len(test_loader.dataset)\n",
    "\n",
    "    # Оценка точности на тестовой выборке\n",
    "    accuracy_val = run_acc_test / len(test_loader)\n",
    "    \n",
    "    # Оценка precision на тестовой выборке\n",
    "    precision_val = prec_acc_test / len(test_loader)\n",
    "\n",
    "    # Обновляем переменную для лучшей потери\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model_classifier.state_dict(), 'best_model.pt')\n",
    "\n",
    "    # Сохраняем потери для данной эпохи\n",
    "    loss_list.append(val_loss)\n",
    "\n",
    "    # Выводим результаты после завершения предыдущей эпохи\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}, Training Loss: {running_loss/len(train_loader.dataset)}, Validation Loss: {val_loss}, Validation Accuracy: {accuracy_val}, Precision: {precision_val}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_list)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
